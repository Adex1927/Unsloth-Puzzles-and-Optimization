{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "bag7rnuih7Ob"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import traceback as tb\n",
        "from functorch.experimental.control_flow import cond\n",
        "\n",
        "torch._logging.set_logs(graph_code=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Basics"
      ],
      "metadata": {
        "id": "zdnzyAAZjOH2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def foo(x, y):\n",
        "    a = torch.sin(x)\n",
        "    b = torch.cos(y)\n",
        "    return a + b\n",
        "\n",
        "\n",
        "opt_foo1 = torch.compile(foo)\n",
        "print(opt_foo1(torch.randn(3, 3), torch.randn(3, 3)))\n",
        "\n",
        "\n",
        "@torch.compile\n",
        "def opt_foo2(x, y):\n",
        "    a = torch.sin(x)\n",
        "    b = torch.cos(y)\n",
        "    return a + b\n",
        "\n",
        "\n",
        "print(opt_foo2(torch.randn(3, 3), torch.randn(3, 3)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8SAQmoeih-Dq",
        "outputId": "5a0d8866-63da-43c1-89a3-ca1886966176"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "V0209 03:54:40.007000 926 torch/_dynamo/output_graph.py:1983] [0/0] [__graph_code] TRACED GRAPH\n",
            "V0209 03:54:40.007000 926 torch/_dynamo/output_graph.py:1983] [0/0] [__graph_code]  ===== __compiled_fn_1_5bd9b235_7c5c_439c_b2dc_f2819823176a =====\n",
            "V0209 03:54:40.007000 926 torch/_dynamo/output_graph.py:1983] [0/0] [__graph_code]  /usr/local/lib/python3.12/dist-packages/torch/fx/_lazy_graph_module.py class GraphModule(torch.nn.Module):\n",
            "V0209 03:54:40.007000 926 torch/_dynamo/output_graph.py:1983] [0/0] [__graph_code]     def forward(self, L_x_: \"f32[3, 3][3, 1]cpu\", L_y_: \"f32[3, 3][3, 1]cpu\"):\n",
            "V0209 03:54:40.007000 926 torch/_dynamo/output_graph.py:1983] [0/0] [__graph_code]         l_x_ = L_x_\n",
            "V0209 03:54:40.007000 926 torch/_dynamo/output_graph.py:1983] [0/0] [__graph_code]         l_y_ = L_y_\n",
            "V0209 03:54:40.007000 926 torch/_dynamo/output_graph.py:1983] [0/0] [__graph_code]         \n",
            "V0209 03:54:40.007000 926 torch/_dynamo/output_graph.py:1983] [0/0] [__graph_code]          # File: /tmp/ipython-input-1190750881.py:2 in foo, code: a = torch.sin(x)\n",
            "V0209 03:54:40.007000 926 torch/_dynamo/output_graph.py:1983] [0/0] [__graph_code]         a: \"f32[3, 3][3, 1]cpu\" = torch.sin(l_x_);  l_x_ = None\n",
            "V0209 03:54:40.007000 926 torch/_dynamo/output_graph.py:1983] [0/0] [__graph_code]         \n",
            "V0209 03:54:40.007000 926 torch/_dynamo/output_graph.py:1983] [0/0] [__graph_code]          # File: /tmp/ipython-input-1190750881.py:3 in foo, code: b = torch.cos(y)\n",
            "V0209 03:54:40.007000 926 torch/_dynamo/output_graph.py:1983] [0/0] [__graph_code]         b: \"f32[3, 3][3, 1]cpu\" = torch.cos(l_y_);  l_y_ = None\n",
            "V0209 03:54:40.007000 926 torch/_dynamo/output_graph.py:1983] [0/0] [__graph_code]         \n",
            "V0209 03:54:40.007000 926 torch/_dynamo/output_graph.py:1983] [0/0] [__graph_code]          # File: /tmp/ipython-input-1190750881.py:4 in foo, code: return a + b\n",
            "V0209 03:54:40.007000 926 torch/_dynamo/output_graph.py:1983] [0/0] [__graph_code]         add: \"f32[3, 3][3, 1]cpu\" = a + b;  a = b = None\n",
            "V0209 03:54:40.007000 926 torch/_dynamo/output_graph.py:1983] [0/0] [__graph_code]         return (add,)\n",
            "V0209 03:54:40.007000 926 torch/_dynamo/output_graph.py:1983] [0/0] [__graph_code]         \n",
            "V0209 03:54:40.007000 926 torch/_dynamo/output_graph.py:1983] [0/0] [__graph_code] \n",
            "V0209 03:54:55.607000 926 torch/_dynamo/output_graph.py:1983] [1/0] [__graph_code] TRACED GRAPH\n",
            "V0209 03:54:55.607000 926 torch/_dynamo/output_graph.py:1983] [1/0] [__graph_code]  ===== __compiled_fn_3_9ee5105f_8d28_4aca_b29c_ad4c9c21b6f6 =====\n",
            "V0209 03:54:55.607000 926 torch/_dynamo/output_graph.py:1983] [1/0] [__graph_code]  /usr/local/lib/python3.12/dist-packages/torch/fx/_lazy_graph_module.py class GraphModule(torch.nn.Module):\n",
            "V0209 03:54:55.607000 926 torch/_dynamo/output_graph.py:1983] [1/0] [__graph_code]     def forward(self, L_x_: \"f32[3, 3][3, 1]cpu\", L_y_: \"f32[3, 3][3, 1]cpu\"):\n",
            "V0209 03:54:55.607000 926 torch/_dynamo/output_graph.py:1983] [1/0] [__graph_code]         l_x_ = L_x_\n",
            "V0209 03:54:55.607000 926 torch/_dynamo/output_graph.py:1983] [1/0] [__graph_code]         l_y_ = L_y_\n",
            "V0209 03:54:55.607000 926 torch/_dynamo/output_graph.py:1983] [1/0] [__graph_code]         \n",
            "V0209 03:54:55.607000 926 torch/_dynamo/output_graph.py:1983] [1/0] [__graph_code]          # File: /tmp/ipython-input-1190750881.py:13 in opt_foo2, code: a = torch.sin(x)\n",
            "V0209 03:54:55.607000 926 torch/_dynamo/output_graph.py:1983] [1/0] [__graph_code]         a: \"f32[3, 3][3, 1]cpu\" = torch.sin(l_x_);  l_x_ = None\n",
            "V0209 03:54:55.607000 926 torch/_dynamo/output_graph.py:1983] [1/0] [__graph_code]         \n",
            "V0209 03:54:55.607000 926 torch/_dynamo/output_graph.py:1983] [1/0] [__graph_code]          # File: /tmp/ipython-input-1190750881.py:14 in opt_foo2, code: b = torch.cos(y)\n",
            "V0209 03:54:55.607000 926 torch/_dynamo/output_graph.py:1983] [1/0] [__graph_code]         b: \"f32[3, 3][3, 1]cpu\" = torch.cos(l_y_);  l_y_ = None\n",
            "V0209 03:54:55.607000 926 torch/_dynamo/output_graph.py:1983] [1/0] [__graph_code]         \n",
            "V0209 03:54:55.607000 926 torch/_dynamo/output_graph.py:1983] [1/0] [__graph_code]          # File: /tmp/ipython-input-1190750881.py:15 in opt_foo2, code: return a + b\n",
            "V0209 03:54:55.607000 926 torch/_dynamo/output_graph.py:1983] [1/0] [__graph_code]         add: \"f32[3, 3][3, 1]cpu\" = a + b;  a = b = None\n",
            "V0209 03:54:55.607000 926 torch/_dynamo/output_graph.py:1983] [1/0] [__graph_code]         return (add,)\n",
            "V0209 03:54:55.607000 926 torch/_dynamo/output_graph.py:1983] [1/0] [__graph_code]         \n",
            "V0209 03:54:55.607000 926 torch/_dynamo/output_graph.py:1983] [1/0] [__graph_code] \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[ 1.8430,  0.0587,  0.1466],\n",
            "        [ 1.0785, -0.8453,  1.3462],\n",
            "        [-0.1504,  0.6011,  0.4347]])\n",
            "tensor([[ 1.4312,  1.9973, -0.6420],\n",
            "        [ 1.0545,  0.8127,  1.6647],\n",
            "        [-0.3056,  1.3990,  1.2609]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def inner(x):\n",
        "    return torch.sin(x)\n",
        "\n",
        "\n",
        "@torch.compile\n",
        "def outer(x, y):\n",
        "    a = inner(x)\n",
        "    b = torch.cos(y)\n",
        "    return a + b\n",
        "\n",
        "\n",
        "print(outer(torch.randn(3, 3), torch.randn(3, 3)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pPp-iWt-iUq4",
        "outputId": "3ac32d1f-c0c9-4c73-b6d6-0a1a6bc7bc80"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "V0209 03:58:17.994000 926 torch/_dynamo/output_graph.py:1983] [2/0] [__graph_code] TRACED GRAPH\n",
            "V0209 03:58:17.994000 926 torch/_dynamo/output_graph.py:1983] [2/0] [__graph_code]  ===== __compiled_fn_5_5af9f1b7_44f4_448d_b25c_41b2bd9ba27e =====\n",
            "V0209 03:58:17.994000 926 torch/_dynamo/output_graph.py:1983] [2/0] [__graph_code]  /usr/local/lib/python3.12/dist-packages/torch/fx/_lazy_graph_module.py class GraphModule(torch.nn.Module):\n",
            "V0209 03:58:17.994000 926 torch/_dynamo/output_graph.py:1983] [2/0] [__graph_code]     def forward(self, L_x_: \"f32[3, 3][3, 1]cpu\", L_y_: \"f32[3, 3][3, 1]cpu\"):\n",
            "V0209 03:58:17.994000 926 torch/_dynamo/output_graph.py:1983] [2/0] [__graph_code]         l_x_ = L_x_\n",
            "V0209 03:58:17.994000 926 torch/_dynamo/output_graph.py:1983] [2/0] [__graph_code]         l_y_ = L_y_\n",
            "V0209 03:58:17.994000 926 torch/_dynamo/output_graph.py:1983] [2/0] [__graph_code]         \n",
            "V0209 03:58:17.994000 926 torch/_dynamo/output_graph.py:1983] [2/0] [__graph_code]          # File: /tmp/ipython-input-2199486826.py:2 in inner, code: return torch.sin(x)\n",
            "V0209 03:58:17.994000 926 torch/_dynamo/output_graph.py:1983] [2/0] [__graph_code]         a: \"f32[3, 3][3, 1]cpu\" = torch.sin(l_x_);  l_x_ = None\n",
            "V0209 03:58:17.994000 926 torch/_dynamo/output_graph.py:1983] [2/0] [__graph_code]         \n",
            "V0209 03:58:17.994000 926 torch/_dynamo/output_graph.py:1983] [2/0] [__graph_code]          # File: /tmp/ipython-input-2199486826.py:8 in outer, code: b = torch.cos(y)\n",
            "V0209 03:58:17.994000 926 torch/_dynamo/output_graph.py:1983] [2/0] [__graph_code]         b: \"f32[3, 3][3, 1]cpu\" = torch.cos(l_y_);  l_y_ = None\n",
            "V0209 03:58:17.994000 926 torch/_dynamo/output_graph.py:1983] [2/0] [__graph_code]         \n",
            "V0209 03:58:17.994000 926 torch/_dynamo/output_graph.py:1983] [2/0] [__graph_code]          # File: /tmp/ipython-input-2199486826.py:9 in outer, code: return a + b\n",
            "V0209 03:58:17.994000 926 torch/_dynamo/output_graph.py:1983] [2/0] [__graph_code]         add: \"f32[3, 3][3, 1]cpu\" = a + b;  a = b = None\n",
            "V0209 03:58:17.994000 926 torch/_dynamo/output_graph.py:1983] [2/0] [__graph_code]         return (add,)\n",
            "V0209 03:58:17.994000 926 torch/_dynamo/output_graph.py:1983] [2/0] [__graph_code]         \n",
            "V0209 03:58:17.994000 926 torch/_dynamo/output_graph.py:1983] [2/0] [__graph_code] \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[ 0.6077,  1.1759,  1.4414],\n",
            "        [-0.8267,  1.8781,  1.2680],\n",
            "        [ 0.0673,  0.3714,  0.1308]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Torch Modules"
      ],
      "metadata": {
        "id": "nztP7K59kPmE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "t = torch.randn(10, 100)\n",
        "\n",
        "\n",
        "class MyModule(torch.nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.lin = torch.nn.Linear(3, 3)\n",
        "\n",
        "    def forward(self, x):\n",
        "        return torch.nn.functional.relu(self.lin(x))\n",
        "\n",
        "\n",
        "mod1 = MyModule()\n",
        "mod1.compile()\n",
        "print(mod1(torch.randn(3, 3)))\n",
        "\n",
        "mod2 = MyModule()\n",
        "mod2 = torch.compile(mod2)\n",
        "print(mod2(torch.randn(3, 3)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "skZQI6CDjNbk",
        "outputId": "9505b5f8-1583-4411-bb0a-f170d392415e"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "V0209 04:03:03.683000 926 torch/_dynamo/output_graph.py:1983] [3/0] [__graph_code] TRACED GRAPH\n",
            "V0209 04:03:03.683000 926 torch/_dynamo/output_graph.py:1983] [3/0] [__graph_code]  ===== __compiled_fn_7_c3138e92_e800_426b_87bd_24279e6678f1 =====\n",
            "V0209 04:03:03.683000 926 torch/_dynamo/output_graph.py:1983] [3/0] [__graph_code]  /usr/local/lib/python3.12/dist-packages/torch/fx/_lazy_graph_module.py class GraphModule(torch.nn.Module):\n",
            "V0209 04:03:03.683000 926 torch/_dynamo/output_graph.py:1983] [3/0] [__graph_code]     def forward(self, L_self_modules_lin_parameters_weight_: \"f32[3, 3][3, 1]cpu\", L_self_modules_lin_parameters_bias_: \"f32[3][1]cpu\", L_x_: \"f32[3, 3][3, 1]cpu\"):\n",
            "V0209 04:03:03.683000 926 torch/_dynamo/output_graph.py:1983] [3/0] [__graph_code]         l_self_modules_lin_parameters_weight_ = L_self_modules_lin_parameters_weight_\n",
            "V0209 04:03:03.683000 926 torch/_dynamo/output_graph.py:1983] [3/0] [__graph_code]         l_self_modules_lin_parameters_bias_ = L_self_modules_lin_parameters_bias_\n",
            "V0209 04:03:03.683000 926 torch/_dynamo/output_graph.py:1983] [3/0] [__graph_code]         l_x_ = L_x_\n",
            "V0209 04:03:03.683000 926 torch/_dynamo/output_graph.py:1983] [3/0] [__graph_code]         \n",
            "V0209 04:03:03.683000 926 torch/_dynamo/output_graph.py:1983] [3/0] [__graph_code]          # File: /tmp/ipython-input-1755088953.py:10 in forward, code: return torch.nn.functional.relu(self.lin(x))\n",
            "V0209 04:03:03.683000 926 torch/_dynamo/output_graph.py:1983] [3/0] [__graph_code]         linear: \"f32[3, 3][3, 1]cpu\" = torch._C._nn.linear(l_x_, l_self_modules_lin_parameters_weight_, l_self_modules_lin_parameters_bias_);  l_x_ = l_self_modules_lin_parameters_weight_ = l_self_modules_lin_parameters_bias_ = None\n",
            "V0209 04:03:03.683000 926 torch/_dynamo/output_graph.py:1983] [3/0] [__graph_code]         relu: \"f32[3, 3][3, 1]cpu\" = torch.nn.functional.relu(linear);  linear = None\n",
            "V0209 04:03:03.683000 926 torch/_dynamo/output_graph.py:1983] [3/0] [__graph_code]         return (relu,)\n",
            "V0209 04:03:03.683000 926 torch/_dynamo/output_graph.py:1983] [3/0] [__graph_code]         \n",
            "V0209 04:03:03.683000 926 torch/_dynamo/output_graph.py:1983] [3/0] [__graph_code] \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0.0000, 0.4400, 0.3770],\n",
            "        [0.0000, 0.9943, 0.2302],\n",
            "        [0.0000, 1.1746, 0.6812]], grad_fn=<CompiledFunctionBackward>)\n",
            "tensor([[0.0000, 0.0000, 0.3902],\n",
            "        [0.3950, 0.0000, 0.3283],\n",
            "        [0.4503, 0.0000, 0.0000]], grad_fn=<CompiledFunctionBackward>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Speedup Demo"
      ],
      "metadata": {
        "id": "CCvGCSbUlFVq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def foo3(x):\n",
        "    y = x + 1\n",
        "    z = torch.nn.functional.relu(y)\n",
        "    u = z * 2\n",
        "    return u\n",
        "\n",
        "\n",
        "opt_foo3 = torch.compile(foo3)\n",
        "\n",
        "\n",
        "# Returns the result of running `fn()` and the time it took for `fn()` to run,\n",
        "# in seconds. We use CUDA events and synchronization for the most accurate\n",
        "# measurements.\n",
        "def timed(fn):\n",
        "    start = torch.cuda.Event(enable_timing=True)\n",
        "    end = torch.cuda.Event(enable_timing=True)\n",
        "    start.record()\n",
        "    result = fn()\n",
        "    end.record()\n",
        "    torch.cuda.synchronize()\n",
        "    return result, start.elapsed_time(end) / 1000\n",
        "\n",
        "\n",
        "inp = torch.randn(4096, 4096).cuda()\n",
        "# print(\"compile:\", timed(lambda: opt_foo3(inp))[1])\n",
        "# print(\"eager:\", timed(lambda: foo3(inp))[1])"
      ],
      "metadata": {
        "id": "TKuZ1k91kTJ3"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# turn off logging for now to prevent spam\n",
        "torch._logging.set_logs(graph_code=False)\n",
        "\n",
        "eager_times = []\n",
        "for i in range(10):\n",
        "    _, eager_time = timed(lambda: foo3(inp))\n",
        "    eager_times.append(eager_time)\n",
        "    print(f\"eager time {i}: {eager_time}\")\n",
        "print(\"~\" * 10)\n",
        "\n",
        "compile_times = []\n",
        "for i in range(10):\n",
        "    _, compile_time = timed(lambda: opt_foo3(inp))\n",
        "    compile_times.append(compile_time)\n",
        "    print(f\"compile time {i}: {compile_time}\")\n",
        "print(\"~\" * 10)\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "eager_med = np.median(eager_times)\n",
        "compile_med = np.median(compile_times)\n",
        "speedup = eager_med / compile_med\n",
        "assert speedup > 1\n",
        "print(\n",
        "    f\"(eval) eager median: {eager_med}, compile median: {compile_med}, speedup: {speedup}x\"\n",
        ")\n",
        "print(\"~\" * 10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T1GHPQJslbON",
        "outputId": "04be9c71-5e3c-4d9f-c2d7-2255f1b26f06"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "eager time 0: 0.001882688045501709\n",
            "eager time 1: 0.0019129279851913452\n",
            "eager time 2: 0.0017240320444107055\n",
            "eager time 3: 0.0017167359590530395\n",
            "eager time 4: 0.0017345600128173828\n",
            "eager time 5: 0.0017388479709625243\n",
            "eager time 6: 0.0017455040216445923\n",
            "eager time 7: 0.001720960021018982\n",
            "eager time 8: 0.0017236160039901733\n",
            "eager time 9: 0.0017163840532302857\n",
            "~~~~~~~~~~\n",
            "compile time 0: 0.0008069120049476623\n",
            "compile time 1: 0.0007274240255355835\n",
            "compile time 2: 0.0006666560173034668\n",
            "compile time 3: 0.0006573759913444519\n",
            "compile time 4: 0.0006492159962654114\n",
            "compile time 5: 0.0006516799926757813\n",
            "compile time 6: 0.0006692799925804139\n",
            "compile time 7: 0.0006451519727706909\n",
            "compile time 8: 0.0006405760049819946\n",
            "compile time 9: 0.0006440960168838501\n",
            "~~~~~~~~~~\n",
            "(eval) eager median: 0.0017292960286140443, compile median: 0.0006545279920101166, speedup: 2.6420505306476114x\n",
            "~~~~~~~~~~\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## TorchScript Comparison"
      ],
      "metadata": {
        "id": "imGVFb6GoI5F"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def f1(x, y):\n",
        "    if x.sum() < 0:\n",
        "        return -y\n",
        "    return y\n",
        "\n",
        "\n",
        "# Test that `fn1` and `fn2` return the same result, given the same arguments `args`.\n",
        "def test_fns(fn1, fn2, args):\n",
        "    out1 = fn1(*args)\n",
        "    out2 = fn2(*args)\n",
        "    return torch.allclose(out1, out2)\n",
        "\n",
        "\n",
        "inp1 = torch.randn(5, 5)\n",
        "inp2 = torch.randn(5, 5)\n",
        "\n",
        "traced_f1 = torch.jit.trace(f1, (inp1, inp2))\n",
        "print(\"traced 1, 1:\", test_fns(f1, traced_f1, (inp1, inp2)))\n",
        "print(\"traced 1, 2:\", test_fns(f1, traced_f1, (-inp1, inp2)))\n",
        "\n",
        "compile_f1 = torch.compile(f1)\n",
        "print(\"compile 1, 1:\", test_fns(f1, compile_f1, (inp1, inp2)))\n",
        "print(\"compile 1, 2:\", test_fns(f1, compile_f1, (-inp1, inp2)))\n",
        "print(\"~\" * 10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6j0OBNJQmsrH",
        "outputId": "9bc5c4a2-9afe-49ff-903f-e33f2d0967bc"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-65032246.py:2: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
            "  if x.sum() < 0:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "traced 1, 1: True\n",
            "traced 1, 2: False\n",
            "compile 1, 1: True\n",
            "compile 1, 2: True\n",
            "~~~~~~~~~~\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch._logging.set_logs(graph_code=True)\n",
        "\n",
        "\n",
        "def f2(x, y):\n",
        "    return x + y\n",
        "\n",
        "\n",
        "inp1 = torch.randn(5, 5)\n",
        "inp2 = 3\n",
        "\n",
        "script_f2 = torch.jit.script(f2)\n",
        "try:\n",
        "    script_f2(inp1, inp2)\n",
        "except:\n",
        "    tb.print_exc()\n",
        "\n",
        "compile_f2 = torch.compile(f2)\n",
        "print(\"compile 2:\", test_fns(f2, compile_f2, (inp1, inp2)))\n",
        "print(\"~\" * 10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6iJ5oWZgoLJl",
        "outputId": "7c0699f2-3e52-47bc-89f8-a2304bde1344"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/tmp/ipython-input-3652677659.py\", line 15, in <cell line: 0>\n",
            "    script_f2(inp1, inp2)\n",
            "RuntimeError: f2() Expected a value of type 'Tensor (inferred)' for argument 'y' but instead found type 'int'.\n",
            "Inferred 'y' to be of type 'Tensor' because it was not annotated with an explicit type.\n",
            "Position: 1\n",
            "Value: 3\n",
            "Declaration: f2(Tensor x, Tensor y) -> Tensor\n",
            "Cast error details: Unable to cast 3 to Tensor\n",
            "V0209 04:24:12.132000 435 torch/_dynamo/output_graph.py:1983] [4/0] [__graph_code] TRACED GRAPH\n",
            "V0209 04:24:12.132000 435 torch/_dynamo/output_graph.py:1983] [4/0] [__graph_code]  ===== __compiled_fn_10_1ebbd991_8d47_4d5d_a7d1_236cd1b30dc8 =====\n",
            "V0209 04:24:12.132000 435 torch/_dynamo/output_graph.py:1983] [4/0] [__graph_code]  /usr/local/lib/python3.12/dist-packages/torch/fx/_lazy_graph_module.py class GraphModule(torch.nn.Module):\n",
            "V0209 04:24:12.132000 435 torch/_dynamo/output_graph.py:1983] [4/0] [__graph_code]     def forward(self, L_x_: \"f32[5, 5][5, 1]cpu\"):\n",
            "V0209 04:24:12.132000 435 torch/_dynamo/output_graph.py:1983] [4/0] [__graph_code]         l_x_ = L_x_\n",
            "V0209 04:24:12.132000 435 torch/_dynamo/output_graph.py:1983] [4/0] [__graph_code]         \n",
            "V0209 04:24:12.132000 435 torch/_dynamo/output_graph.py:1983] [4/0] [__graph_code]          # File: /tmp/ipython-input-3652677659.py:7 in f2, code: return x + y\n",
            "V0209 04:24:12.132000 435 torch/_dynamo/output_graph.py:1983] [4/0] [__graph_code]         add: \"f32[5, 5][5, 1]cpu\" = l_x_ + 3;  l_x_ = None\n",
            "V0209 04:24:12.132000 435 torch/_dynamo/output_graph.py:1983] [4/0] [__graph_code]         return (add,)\n",
            "V0209 04:24:12.132000 435 torch/_dynamo/output_graph.py:1983] [4/0] [__graph_code]         \n",
            "V0209 04:24:12.132000 435 torch/_dynamo/output_graph.py:1983] [4/0] [__graph_code] \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "compile 2: True\n",
            "~~~~~~~~~~\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Graph Breaks"
      ],
      "metadata": {
        "id": "428GmeP6pyiv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def bar(a, b):\n",
        "    x = a / (torch.abs(a) + 1)\n",
        "    if b.sum() < 0:\n",
        "        b = b * -1\n",
        "    return x * b\n",
        "\n",
        "\n",
        "opt_bar = torch.compile(bar)\n",
        "inp1 = torch.ones(10)\n",
        "inp2 = torch.ones(10)\n",
        "opt_bar(inp1, inp2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2cjOtrDCpbom",
        "outputId": "65cb866a-6430-4d88-b2b7-15a30a18f24d"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "V0209 06:24:20.609000 950 torch/_dynamo/output_graph.py:1983] [1/0] [__graph_code] TRACED GRAPH\n",
            "V0209 06:24:20.609000 950 torch/_dynamo/output_graph.py:1983] [1/0] [__graph_code]  ===== __compiled_fn_18_c3e4e3f1_d6f7_4392_930d_4d53a903df0f =====\n",
            "V0209 06:24:20.609000 950 torch/_dynamo/output_graph.py:1983] [1/0] [__graph_code]  /usr/local/lib/python3.12/dist-packages/torch/fx/_lazy_graph_module.py class GraphModule(torch.nn.Module):\n",
            "V0209 06:24:20.609000 950 torch/_dynamo/output_graph.py:1983] [1/0] [__graph_code]     def forward(self, L_a_: \"f32[10][1]cpu\", L_b_: \"f32[10][1]cpu\"):\n",
            "V0209 06:24:20.609000 950 torch/_dynamo/output_graph.py:1983] [1/0] [__graph_code]         l_a_ = L_a_\n",
            "V0209 06:24:20.609000 950 torch/_dynamo/output_graph.py:1983] [1/0] [__graph_code]         l_b_ = L_b_\n",
            "V0209 06:24:20.609000 950 torch/_dynamo/output_graph.py:1983] [1/0] [__graph_code]         \n",
            "V0209 06:24:20.609000 950 torch/_dynamo/output_graph.py:1983] [1/0] [__graph_code]          # File: /tmp/ipython-input-3700889113.py:2 in bar, code: x = a / (torch.abs(a) + 1)\n",
            "V0209 06:24:20.609000 950 torch/_dynamo/output_graph.py:1983] [1/0] [__graph_code]         abs_1: \"f32[10][1]cpu\" = torch.abs(l_a_)\n",
            "V0209 06:24:20.609000 950 torch/_dynamo/output_graph.py:1983] [1/0] [__graph_code]         add: \"f32[10][1]cpu\" = abs_1 + 1;  abs_1 = None\n",
            "V0209 06:24:20.609000 950 torch/_dynamo/output_graph.py:1983] [1/0] [__graph_code]         x: \"f32[10][1]cpu\" = l_a_ / add;  l_a_ = add = None\n",
            "V0209 06:24:20.609000 950 torch/_dynamo/output_graph.py:1983] [1/0] [__graph_code]         \n",
            "V0209 06:24:20.609000 950 torch/_dynamo/output_graph.py:1983] [1/0] [__graph_code]          # File: /tmp/ipython-input-3700889113.py:3 in bar, code: if b.sum() < 0:\n",
            "V0209 06:24:20.609000 950 torch/_dynamo/output_graph.py:1983] [1/0] [__graph_code]         sum_1: \"f32[][]cpu\" = l_b_.sum();  l_b_ = None\n",
            "V0209 06:24:20.609000 950 torch/_dynamo/output_graph.py:1983] [1/0] [__graph_code]         lt: \"b8[][]cpu\" = sum_1 < 0;  sum_1 = None\n",
            "V0209 06:24:20.609000 950 torch/_dynamo/output_graph.py:1983] [1/0] [__graph_code]         return (lt, x)\n",
            "V0209 06:24:20.609000 950 torch/_dynamo/output_graph.py:1983] [1/0] [__graph_code]         \n",
            "V0209 06:24:20.609000 950 torch/_dynamo/output_graph.py:1983] [1/0] [__graph_code] \n",
            "V0209 06:24:20.666000 950 torch/_dynamo/output_graph.py:1983] [2/0] [__graph_code] TRACED GRAPH\n",
            "V0209 06:24:20.666000 950 torch/_dynamo/output_graph.py:1983] [2/0] [__graph_code]  ===== __compiled_fn_22_77abb607_6b91_4edb_a1c3_a56329b2e54b =====\n",
            "V0209 06:24:20.666000 950 torch/_dynamo/output_graph.py:1983] [2/0] [__graph_code]  /usr/local/lib/python3.12/dist-packages/torch/fx/_lazy_graph_module.py class GraphModule(torch.nn.Module):\n",
            "V0209 06:24:20.666000 950 torch/_dynamo/output_graph.py:1983] [2/0] [__graph_code]     def forward(self, L_x_: \"f32[10][1]cpu\", L_b_: \"f32[10][1]cpu\"):\n",
            "V0209 06:24:20.666000 950 torch/_dynamo/output_graph.py:1983] [2/0] [__graph_code]         l_x_ = L_x_\n",
            "V0209 06:24:20.666000 950 torch/_dynamo/output_graph.py:1983] [2/0] [__graph_code]         l_b_ = L_b_\n",
            "V0209 06:24:20.666000 950 torch/_dynamo/output_graph.py:1983] [2/0] [__graph_code]         \n",
            "V0209 06:24:20.666000 950 torch/_dynamo/output_graph.py:1983] [2/0] [__graph_code]          # File: /tmp/ipython-input-3700889113.py:5 in torch_dynamo_resume_in_bar_at_3, code: return x * b\n",
            "V0209 06:24:20.666000 950 torch/_dynamo/output_graph.py:1983] [2/0] [__graph_code]         mul: \"f32[10][1]cpu\" = l_x_ * l_b_;  l_x_ = l_b_ = None\n",
            "V0209 06:24:20.666000 950 torch/_dynamo/output_graph.py:1983] [2/0] [__graph_code]         return (mul,)\n",
            "V0209 06:24:20.666000 950 torch/_dynamo/output_graph.py:1983] [2/0] [__graph_code]         \n",
            "V0209 06:24:20.666000 950 torch/_dynamo/output_graph.py:1983] [2/0] [__graph_code] \n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000,\n",
              "        0.5000])"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "opt_bar(inp1, -inp2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Pkv4-Dy-q4sH",
        "outputId": "1179ccc3-dc40-45e5-e7e4-7aeedac18819"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "V0209 06:24:21.182000 950 torch/_dynamo/output_graph.py:1983] [3/0] [__graph_code] TRACED GRAPH\n",
            "V0209 06:24:21.182000 950 torch/_dynamo/output_graph.py:1983] [3/0] [__graph_code]  ===== __compiled_fn_24_ef61c6ba_0cf7_4f88_94f4_297fb9600c28 =====\n",
            "V0209 06:24:21.182000 950 torch/_dynamo/output_graph.py:1983] [3/0] [__graph_code]  /usr/local/lib/python3.12/dist-packages/torch/fx/_lazy_graph_module.py class GraphModule(torch.nn.Module):\n",
            "V0209 06:24:21.182000 950 torch/_dynamo/output_graph.py:1983] [3/0] [__graph_code]     def forward(self, L_b_: \"f32[10][1]cpu\", L_x_: \"f32[10][1]cpu\"):\n",
            "V0209 06:24:21.182000 950 torch/_dynamo/output_graph.py:1983] [3/0] [__graph_code]         l_b_ = L_b_\n",
            "V0209 06:24:21.182000 950 torch/_dynamo/output_graph.py:1983] [3/0] [__graph_code]         l_x_ = L_x_\n",
            "V0209 06:24:21.182000 950 torch/_dynamo/output_graph.py:1983] [3/0] [__graph_code]         \n",
            "V0209 06:24:21.182000 950 torch/_dynamo/output_graph.py:1983] [3/0] [__graph_code]          # File: /tmp/ipython-input-3700889113.py:4 in torch_dynamo_resume_in_bar_at_3, code: b = b * -1\n",
            "V0209 06:24:21.182000 950 torch/_dynamo/output_graph.py:1983] [3/0] [__graph_code]         b: \"f32[10][1]cpu\" = l_b_ * -1;  l_b_ = None\n",
            "V0209 06:24:21.182000 950 torch/_dynamo/output_graph.py:1983] [3/0] [__graph_code]         \n",
            "V0209 06:24:21.182000 950 torch/_dynamo/output_graph.py:1983] [3/0] [__graph_code]          # File: /tmp/ipython-input-3700889113.py:5 in torch_dynamo_resume_in_bar_at_3, code: return x * b\n",
            "V0209 06:24:21.182000 950 torch/_dynamo/output_graph.py:1983] [3/0] [__graph_code]         mul_1: \"f32[10][1]cpu\" = l_x_ * b;  l_x_ = b = None\n",
            "V0209 06:24:21.182000 950 torch/_dynamo/output_graph.py:1983] [3/0] [__graph_code]         return (mul_1,)\n",
            "V0209 06:24:21.182000 950 torch/_dynamo/output_graph.py:1983] [3/0] [__graph_code]         \n",
            "V0209 06:24:21.182000 950 torch/_dynamo/output_graph.py:1983] [3/0] [__graph_code] \n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000,\n",
              "        0.5000])"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Reset to clear the torch.compile cache\n",
        "torch._dynamo.reset()\n",
        "opt_bar(inp1, inp2)\n",
        "opt_bar(inp1, -inp2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rs46KnG-q5x8",
        "outputId": "84ebb571-36cb-4919-c9f9-481a6a8a2e83"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "V0209 06:24:22.544000 950 torch/_dynamo/output_graph.py:1983] [0/0] [__graph_code] TRACED GRAPH\n",
            "V0209 06:24:22.544000 950 torch/_dynamo/output_graph.py:1983] [0/0] [__graph_code]  ===== __compiled_fn_26_fb8ad3cf_e08d_4cab_8843_e799fbc2c4fa =====\n",
            "V0209 06:24:22.544000 950 torch/_dynamo/output_graph.py:1983] [0/0] [__graph_code]  /usr/local/lib/python3.12/dist-packages/torch/fx/_lazy_graph_module.py class GraphModule(torch.nn.Module):\n",
            "V0209 06:24:22.544000 950 torch/_dynamo/output_graph.py:1983] [0/0] [__graph_code]     def forward(self, L_a_: \"f32[10][1]cpu\", L_b_: \"f32[10][1]cpu\"):\n",
            "V0209 06:24:22.544000 950 torch/_dynamo/output_graph.py:1983] [0/0] [__graph_code]         l_a_ = L_a_\n",
            "V0209 06:24:22.544000 950 torch/_dynamo/output_graph.py:1983] [0/0] [__graph_code]         l_b_ = L_b_\n",
            "V0209 06:24:22.544000 950 torch/_dynamo/output_graph.py:1983] [0/0] [__graph_code]         \n",
            "V0209 06:24:22.544000 950 torch/_dynamo/output_graph.py:1983] [0/0] [__graph_code]          # File: /tmp/ipython-input-3700889113.py:2 in bar, code: x = a / (torch.abs(a) + 1)\n",
            "V0209 06:24:22.544000 950 torch/_dynamo/output_graph.py:1983] [0/0] [__graph_code]         abs_1: \"f32[10][1]cpu\" = torch.abs(l_a_)\n",
            "V0209 06:24:22.544000 950 torch/_dynamo/output_graph.py:1983] [0/0] [__graph_code]         add: \"f32[10][1]cpu\" = abs_1 + 1;  abs_1 = None\n",
            "V0209 06:24:22.544000 950 torch/_dynamo/output_graph.py:1983] [0/0] [__graph_code]         x: \"f32[10][1]cpu\" = l_a_ / add;  l_a_ = add = None\n",
            "V0209 06:24:22.544000 950 torch/_dynamo/output_graph.py:1983] [0/0] [__graph_code]         \n",
            "V0209 06:24:22.544000 950 torch/_dynamo/output_graph.py:1983] [0/0] [__graph_code]          # File: /tmp/ipython-input-3700889113.py:3 in bar, code: if b.sum() < 0:\n",
            "V0209 06:24:22.544000 950 torch/_dynamo/output_graph.py:1983] [0/0] [__graph_code]         sum_1: \"f32[][]cpu\" = l_b_.sum();  l_b_ = None\n",
            "V0209 06:24:22.544000 950 torch/_dynamo/output_graph.py:1983] [0/0] [__graph_code]         lt: \"b8[][]cpu\" = sum_1 < 0;  sum_1 = None\n",
            "V0209 06:24:22.544000 950 torch/_dynamo/output_graph.py:1983] [0/0] [__graph_code]         return (lt, x)\n",
            "V0209 06:24:22.544000 950 torch/_dynamo/output_graph.py:1983] [0/0] [__graph_code]         \n",
            "V0209 06:24:22.544000 950 torch/_dynamo/output_graph.py:1983] [0/0] [__graph_code] \n",
            "V0209 06:24:22.600000 950 torch/_dynamo/output_graph.py:1983] [1/0] [__graph_code] TRACED GRAPH\n",
            "V0209 06:24:22.600000 950 torch/_dynamo/output_graph.py:1983] [1/0] [__graph_code]  ===== __compiled_fn_30_553e4824_6e45_4786_ae43_8b657721ba72 =====\n",
            "V0209 06:24:22.600000 950 torch/_dynamo/output_graph.py:1983] [1/0] [__graph_code]  /usr/local/lib/python3.12/dist-packages/torch/fx/_lazy_graph_module.py class GraphModule(torch.nn.Module):\n",
            "V0209 06:24:22.600000 950 torch/_dynamo/output_graph.py:1983] [1/0] [__graph_code]     def forward(self, L_x_: \"f32[10][1]cpu\", L_b_: \"f32[10][1]cpu\"):\n",
            "V0209 06:24:22.600000 950 torch/_dynamo/output_graph.py:1983] [1/0] [__graph_code]         l_x_ = L_x_\n",
            "V0209 06:24:22.600000 950 torch/_dynamo/output_graph.py:1983] [1/0] [__graph_code]         l_b_ = L_b_\n",
            "V0209 06:24:22.600000 950 torch/_dynamo/output_graph.py:1983] [1/0] [__graph_code]         \n",
            "V0209 06:24:22.600000 950 torch/_dynamo/output_graph.py:1983] [1/0] [__graph_code]          # File: /tmp/ipython-input-3700889113.py:5 in torch_dynamo_resume_in_bar_at_3, code: return x * b\n",
            "V0209 06:24:22.600000 950 torch/_dynamo/output_graph.py:1983] [1/0] [__graph_code]         mul: \"f32[10][1]cpu\" = l_x_ * l_b_;  l_x_ = l_b_ = None\n",
            "V0209 06:24:22.600000 950 torch/_dynamo/output_graph.py:1983] [1/0] [__graph_code]         return (mul,)\n",
            "V0209 06:24:22.600000 950 torch/_dynamo/output_graph.py:1983] [1/0] [__graph_code]         \n",
            "V0209 06:24:22.600000 950 torch/_dynamo/output_graph.py:1983] [1/0] [__graph_code] \n",
            "V0209 06:24:22.671000 950 torch/_dynamo/output_graph.py:1983] [2/0] [__graph_code] TRACED GRAPH\n",
            "V0209 06:24:22.671000 950 torch/_dynamo/output_graph.py:1983] [2/0] [__graph_code]  ===== __compiled_fn_32_326aa27f_6d1d_4405_89b9_76df771c3618 =====\n",
            "V0209 06:24:22.671000 950 torch/_dynamo/output_graph.py:1983] [2/0] [__graph_code]  /usr/local/lib/python3.12/dist-packages/torch/fx/_lazy_graph_module.py class GraphModule(torch.nn.Module):\n",
            "V0209 06:24:22.671000 950 torch/_dynamo/output_graph.py:1983] [2/0] [__graph_code]     def forward(self, L_b_: \"f32[10][1]cpu\", L_x_: \"f32[10][1]cpu\"):\n",
            "V0209 06:24:22.671000 950 torch/_dynamo/output_graph.py:1983] [2/0] [__graph_code]         l_b_ = L_b_\n",
            "V0209 06:24:22.671000 950 torch/_dynamo/output_graph.py:1983] [2/0] [__graph_code]         l_x_ = L_x_\n",
            "V0209 06:24:22.671000 950 torch/_dynamo/output_graph.py:1983] [2/0] [__graph_code]         \n",
            "V0209 06:24:22.671000 950 torch/_dynamo/output_graph.py:1983] [2/0] [__graph_code]          # File: /tmp/ipython-input-3700889113.py:4 in torch_dynamo_resume_in_bar_at_3, code: b = b * -1\n",
            "V0209 06:24:22.671000 950 torch/_dynamo/output_graph.py:1983] [2/0] [__graph_code]         b: \"f32[10][1]cpu\" = l_b_ * -1;  l_b_ = None\n",
            "V0209 06:24:22.671000 950 torch/_dynamo/output_graph.py:1983] [2/0] [__graph_code]         \n",
            "V0209 06:24:22.671000 950 torch/_dynamo/output_graph.py:1983] [2/0] [__graph_code]          # File: /tmp/ipython-input-3700889113.py:5 in torch_dynamo_resume_in_bar_at_3, code: return x * b\n",
            "V0209 06:24:22.671000 950 torch/_dynamo/output_graph.py:1983] [2/0] [__graph_code]         mul_1: \"f32[10][1]cpu\" = l_x_ * b;  l_x_ = b = None\n",
            "V0209 06:24:22.671000 950 torch/_dynamo/output_graph.py:1983] [2/0] [__graph_code]         return (mul_1,)\n",
            "V0209 06:24:22.671000 950 torch/_dynamo/output_graph.py:1983] [2/0] [__graph_code]         \n",
            "V0209 06:24:22.671000 950 torch/_dynamo/output_graph.py:1983] [2/0] [__graph_code] \n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000,\n",
              "        0.5000])"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Reset to clear the torch.compile cache\n",
        "torch._dynamo.reset()\n",
        "\n",
        "opt_bar_fullgraph = torch.compile(bar, fullgraph=True)\n",
        "try:\n",
        "    opt_bar_fullgraph(torch.randn(10), torch.randn(10))\n",
        "except:\n",
        "    tb.print_exc()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1QkYH2YGDq2W",
        "outputId": "4451f075-a129-4776-fc69-0872b145300e"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/tmp/ipython-input-387069252.py\", line 6, in <cell line: 0>\n",
            "    opt_bar_fullgraph(torch.randn(10), torch.randn(10))\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/_dynamo/eval_frame.py\", line 841, in compile_wrapper\n",
            "    raise e.with_traceback(None) from e.__cause__  # User compiler error\n",
            "    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "torch._dynamo.exc.Unsupported: Data-dependent branching\n",
            "  Explanation: Detected data-dependent branching (e.g. `if my_tensor.sum() > 0:`). Dynamo does not support tracing dynamic control flow.\n",
            "  Hint: This graph break is fundamental - it is unlikely that Dynamo will ever be able to trace through your code. Consider finding a workaround.\n",
            "  Hint: Use `torch.cond` to express dynamic control flow.\n",
            "\n",
            "  Developer debug context: attempted to jump with TensorVariable()\n",
            "\n",
            " For more details about this graph break, please visit: https://meta-pytorch.github.io/compile-graph-break-site/gb/gb0170.html\n",
            "\n",
            "from user code:\n",
            "   File \"/tmp/ipython-input-3700889113.py\", line 3, in bar\n",
            "    if b.sum() < 0:\n",
            "\n",
            "Set TORCHDYNAMO_VERBOSE=1 for the internal stack trace (please do this especially if you're reporting a bug to PyTorch). For even more developer context, set TORCH_LOGS=\"+dynamo\"\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "@torch.compile(fullgraph=True)\n",
        "def bar_fixed(a, b):\n",
        "    x = a / (torch.abs(a) + 1)\n",
        "\n",
        "    def true_branch(y):\n",
        "        return y * -1\n",
        "\n",
        "    def false_branch(y):\n",
        "        # NOTE: torch.cond doesn't allow aliased outputs\n",
        "        return y.clone()\n",
        "\n",
        "    b = cond(b.sum() < 0, true_branch, false_branch, (b,))\n",
        "    return x * b\n",
        "\n",
        "\n",
        "bar_fixed(inp1, inp2)\n",
        "bar_fixed(inp1, -inp2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QlBKHBbDEeg3",
        "outputId": "62df5b2b-e316-4171-9338-1806baa96800"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "V0209 06:28:42.417000 950 torch/_dynamo/output_graph.py:1983] [1/0] [__graph_code] TRACED GRAPH\n",
            "V0209 06:28:42.417000 950 torch/_dynamo/output_graph.py:1983] [1/0] [__graph_code]  ===== __compiled_fn_35_8727a923_e9db_42be_9ff3_b856c774bdac =====\n",
            "V0209 06:28:42.417000 950 torch/_dynamo/output_graph.py:1983] [1/0] [__graph_code]  /usr/local/lib/python3.12/dist-packages/torch/fx/_lazy_graph_module.py class GraphModule(torch.nn.Module):\n",
            "V0209 06:28:42.417000 950 torch/_dynamo/output_graph.py:1983] [1/0] [__graph_code]     def forward(self, L_a_: \"f32[10][1]cpu\", L_b_: \"f32[10][1]cpu\"):\n",
            "V0209 06:28:42.417000 950 torch/_dynamo/output_graph.py:1983] [1/0] [__graph_code]         l_a_ = L_a_\n",
            "V0209 06:28:42.417000 950 torch/_dynamo/output_graph.py:1983] [1/0] [__graph_code]         l_b_ = L_b_\n",
            "V0209 06:28:42.417000 950 torch/_dynamo/output_graph.py:1983] [1/0] [__graph_code]         \n",
            "V0209 06:28:42.417000 950 torch/_dynamo/output_graph.py:1983] [1/0] [__graph_code]          # File: /tmp/ipython-input-1080240525.py:3 in bar_fixed, code: x = a / (torch.abs(a) + 1)\n",
            "V0209 06:28:42.417000 950 torch/_dynamo/output_graph.py:1983] [1/0] [__graph_code]         abs_1: \"f32[10][1]cpu\" = torch.abs(l_a_)\n",
            "V0209 06:28:42.417000 950 torch/_dynamo/output_graph.py:1983] [1/0] [__graph_code]         add: \"f32[10][1]cpu\" = abs_1 + 1;  abs_1 = None\n",
            "V0209 06:28:42.417000 950 torch/_dynamo/output_graph.py:1983] [1/0] [__graph_code]         x: \"f32[10][1]cpu\" = l_a_ / add;  l_a_ = add = None\n",
            "V0209 06:28:42.417000 950 torch/_dynamo/output_graph.py:1983] [1/0] [__graph_code]         \n",
            "V0209 06:28:42.417000 950 torch/_dynamo/output_graph.py:1983] [1/0] [__graph_code]          # File: /tmp/ipython-input-1080240525.py:12 in bar_fixed, code: b = cond(b.sum() < 0, true_branch, false_branch, (b,))\n",
            "V0209 06:28:42.417000 950 torch/_dynamo/output_graph.py:1983] [1/0] [__graph_code]         sum_1: \"f32[][]cpu\" = l_b_.sum()\n",
            "V0209 06:28:42.417000 950 torch/_dynamo/output_graph.py:1983] [1/0] [__graph_code]         lt: \"b8[][]cpu\" = sum_1 < 0;  sum_1 = None\n",
            "V0209 06:28:42.417000 950 torch/_dynamo/output_graph.py:1983] [1/0] [__graph_code]         \n",
            "V0209 06:28:42.417000 950 torch/_dynamo/output_graph.py:1983] [1/0] [__graph_code]          # File: /usr/local/lib/python3.12/dist-packages/torch/_higher_order_ops/cond.py:186 in cond, code: return cond_op(pred, true_fn, false_fn, operands)\n",
            "V0209 06:28:42.417000 950 torch/_dynamo/output_graph.py:1983] [1/0] [__graph_code]         cond_true_0 = self.cond_true_0\n",
            "V0209 06:28:42.417000 950 torch/_dynamo/output_graph.py:1983] [1/0] [__graph_code]         cond_false_0 = self.cond_false_0\n",
            "V0209 06:28:42.417000 950 torch/_dynamo/output_graph.py:1983] [1/0] [__graph_code]         cond = torch.ops.higher_order.cond(lt, cond_true_0, cond_false_0, (l_b_,));  lt = cond_true_0 = cond_false_0 = l_b_ = None\n",
            "V0209 06:28:42.417000 950 torch/_dynamo/output_graph.py:1983] [1/0] [__graph_code]         b: \"f32[10][1]cpu\" = cond[0];  cond = None\n",
            "V0209 06:28:42.417000 950 torch/_dynamo/output_graph.py:1983] [1/0] [__graph_code]         \n",
            "V0209 06:28:42.417000 950 torch/_dynamo/output_graph.py:1983] [1/0] [__graph_code]          # File: /tmp/ipython-input-1080240525.py:13 in bar_fixed, code: return x * b\n",
            "V0209 06:28:42.417000 950 torch/_dynamo/output_graph.py:1983] [1/0] [__graph_code]         mul: \"f32[10][1]cpu\" = x * b;  x = b = None\n",
            "V0209 06:28:42.417000 950 torch/_dynamo/output_graph.py:1983] [1/0] [__graph_code]         return (mul,)\n",
            "V0209 06:28:42.417000 950 torch/_dynamo/output_graph.py:1983] [1/0] [__graph_code]         \n",
            "V0209 06:28:42.417000 950 torch/_dynamo/output_graph.py:1983] [1/0] [__graph_code]     class cond_true_0(torch.nn.Module):\n",
            "V0209 06:28:42.417000 950 torch/_dynamo/output_graph.py:1983] [1/0] [__graph_code]         def forward(self, l_b_: \"f32[10][1]cpu\"):\n",
            "V0209 06:28:42.417000 950 torch/_dynamo/output_graph.py:1983] [1/0] [__graph_code]             l_b__1 = l_b_\n",
            "V0209 06:28:42.417000 950 torch/_dynamo/output_graph.py:1983] [1/0] [__graph_code]             \n",
            "V0209 06:28:42.417000 950 torch/_dynamo/output_graph.py:1983] [1/0] [__graph_code]              # File: /tmp/ipython-input-1080240525.py:6 in true_branch, code: return y * -1\n",
            "V0209 06:28:42.417000 950 torch/_dynamo/output_graph.py:1983] [1/0] [__graph_code]             mul: \"f32[10][1]cpu\" = l_b__1 * -1;  l_b__1 = None\n",
            "V0209 06:28:42.417000 950 torch/_dynamo/output_graph.py:1983] [1/0] [__graph_code]             return (mul,)\n",
            "V0209 06:28:42.417000 950 torch/_dynamo/output_graph.py:1983] [1/0] [__graph_code]             \n",
            "V0209 06:28:42.417000 950 torch/_dynamo/output_graph.py:1983] [1/0] [__graph_code]     class cond_false_0(torch.nn.Module):\n",
            "V0209 06:28:42.417000 950 torch/_dynamo/output_graph.py:1983] [1/0] [__graph_code]         def forward(self, l_b_: \"f32[10][1]cpu\"):\n",
            "V0209 06:28:42.417000 950 torch/_dynamo/output_graph.py:1983] [1/0] [__graph_code]             l_b__1 = l_b_\n",
            "V0209 06:28:42.417000 950 torch/_dynamo/output_graph.py:1983] [1/0] [__graph_code]             \n",
            "V0209 06:28:42.417000 950 torch/_dynamo/output_graph.py:1983] [1/0] [__graph_code]              # File: /tmp/ipython-input-1080240525.py:10 in false_branch, code: return y.clone()\n",
            "V0209 06:28:42.417000 950 torch/_dynamo/output_graph.py:1983] [1/0] [__graph_code]             clone: \"f32[10][1]cpu\" = l_b__1.clone();  l_b__1 = None\n",
            "V0209 06:28:42.417000 950 torch/_dynamo/output_graph.py:1983] [1/0] [__graph_code]             return (clone,)\n",
            "V0209 06:28:42.417000 950 torch/_dynamo/output_graph.py:1983] [1/0] [__graph_code]             \n",
            "V0209 06:28:42.417000 950 torch/_dynamo/output_graph.py:1983] [1/0] [__graph_code] \n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000,\n",
              "        0.5000])"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "-hs9-2MlFoqC"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}